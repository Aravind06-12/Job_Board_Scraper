{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiQ8RoldErahmuNEM1C7jV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravind06-12/Job_Board_Scraper/blob/main/job_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4 pandas openpyxl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeclMR6uh6Nl",
        "outputId": "ffe9d3de-10d0-437b-eb77-a7c7fe072bfe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "def main():\n",
        "    keywords = [\"data analyst\"]   # ðŸ‘ˆ change keywords here\n",
        "    keyword_str = \"%2C\".join(keywords)\n",
        "    df = getting_data(keyword_str, max_jobs=30)   # ðŸ‘ˆ limit jobs to run faster\n",
        "\n",
        "    # ðŸ‘‡ Show output in Colab console\n",
        "    print(\"\\nðŸ“Œ Preview of first 10 jobs:\\n\")\n",
        "    print(df.head(10))   # show first 10 rows\n",
        "\n",
        "    # ðŸ‘‡ Save as CSV\n",
        "    df.to_csv(\"jobs.csv\", index=False)\n",
        "    print(\"\\nâœ… Saved as jobs.csv\")\n",
        "\n",
        "    # ðŸ‘‡ For Colab: Download CSV\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(\"jobs.csv\")\n",
        "    except:\n",
        "        print(\"ðŸ“ Download skipped (not running in Colab)\")\n",
        "\n",
        "def getting_data(keywords, max_jobs=50):\n",
        "    all_jobs = []\n",
        "    jobs_scraped = 0\n",
        "    n = 1\n",
        "    condition = True\n",
        "    PAGE_SIZE = 25   # TimesJobs default\n",
        "\n",
        "    while condition:\n",
        "        url = (\n",
        "            f\"https://www.timesjobs.com/candidate/job-search.html?\"\n",
        "            f\"from=submit&actualTxtKeywords={keywords}&searchBy=0&rdoOperator=OR\"\n",
        "            f\"&searchType=personalizedSearch&luceneResultSize={PAGE_SIZE}&postWeek=60\"\n",
        "            f\"&txtKeywords={keywords}&pDate=I&sequence={n}&startPage=1\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"âŒ Request failed: {e}\")\n",
        "            break\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'lxml')\n",
        "\n",
        "        total_tag = soup.find('span', id=\"totolResultCountsId\")\n",
        "        if total_tag:\n",
        "            total = int(total_tag.text)\n",
        "        else:\n",
        "            print(\"âš ï¸ Could not find total results count. Exiting.\")\n",
        "            break\n",
        "\n",
        "        jobs = soup.find_all('li', class_='clearfix job-bx wht-shd-bx')\n",
        "        jobs_scraped += len(jobs)\n",
        "        print(f\"ðŸ”„ Scraped {jobs_scraped}/{min(total, max_jobs)} jobs...\")\n",
        "\n",
        "        for job in jobs:\n",
        "            name = job.find('h2').text.strip() if job.find('h2') else None\n",
        "            company = job.find('h3', class_=\"joblist-comp-name\").text.strip().replace('\\n', '') if job.find('h3', class_=\"joblist-comp-name\") else None\n",
        "            skills = job.find('span', class_=\"srp-skills\").text.strip() if job.find('span', class_=\"srp-skills\") else None\n",
        "            skills = ' '.join(skills.split()) if skills else None\n",
        "            link = job.header.h2.a['href'] if job.header and job.header.h2 and job.header.h2.a else None\n",
        "\n",
        "            # âœ… Fix: Correct Location Extraction\n",
        "            location_tag = job.find('ul', class_='top-jd-dtl clearfix')\n",
        "            location = None\n",
        "            if location_tag:\n",
        "                li_tags = location_tag.find_all('li')\n",
        "                if len(li_tags) > 1:\n",
        "                    location = li_tags[1].text.strip().replace('card_travel', '').strip()\n",
        "\n",
        "            all_jobs.append({\n",
        "                'Position': name,\n",
        "                'Company': company,\n",
        "                'Location': location,\n",
        "                'Skills': skills,\n",
        "                'Link': link,\n",
        "            })\n",
        "\n",
        "        if jobs_scraped >= total or jobs_scraped >= max_jobs:\n",
        "            condition = False\n",
        "        else:\n",
        "            n += 1\n",
        "\n",
        "    return pd.DataFrame(all_jobs[:max_jobs])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "FAxwr4X5uSql",
        "outputId": "1849749b-6b2a-4b09-d5c3-9b725bcf373e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”„ Scraped 25/30 jobs...\n",
            "ðŸ”„ Scraped 50/30 jobs...\n",
            "\n",
            "ðŸ“Œ Preview of first 10 jobs:\n",
            "\n",
            "       Position                          Company Location Skills  \\\n",
            "0  Data Analyst    Novartis Healthcare Pvt. Ltd.     None   None   \n",
            "1  Data Analyst    Novartis Healthcare Pvt. Ltd.     None   None   \n",
            "2  Data Analyst                 Analytics Vidhya     None   None   \n",
            "3  Data analyst                 Analytics Vidhya     None   None   \n",
            "4  Data analyst  BUSISOL SOURCING INDIA PVT. LTD     None   None   \n",
            "5  Data Analyst                  PUBLICIS GROUPE     None   None   \n",
            "6  Data Analyst                 Analytics Vidhya     None   None   \n",
            "7  Data Analyst                 Analytics Vidhya     None   None   \n",
            "8  Data Analyst                 Analytics Vidhya     None   None   \n",
            "9  Data Analyst                 Analytics Vidhya     None   None   \n",
            "\n",
            "                                                Link  \n",
            "0  https://www.timesjobs.com/job-detail/data-anal...  \n",
            "1  https://www.timesjobs.com/job-detail/data-anal...  \n",
            "2  https://www.timesjobs.com/job-detail/data-anal...  \n",
            "3  https://www.timesjobs.com/job-detail/data-anal...  \n",
            "4  https://www.timesjobs.com/job-detail/data-anal...  \n",
            "5  https://www.timesjobs.com/job-detail/data-anal...  \n",
            "6  https://www.timesjobs.com/job-detail/data-anal...  \n",
            "7  https://www.timesjobs.com/job-detail/data-anal...  \n",
            "8  https://www.timesjobs.com/job-detail/data-anal...  \n",
            "9  https://www.timesjobs.com/job-detail/data-anal...  \n",
            "\n",
            "âœ… Saved as jobs.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_de5b4f3e-b7b5-482b-918a-bb99e0324dd5\", \"jobs.csv\", 5381)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}